# RepE

https://arxiv.org/pdf/2310.01405

1. **核心理念：从“表征”入手**  
   与传统的“机械可解释性”（关注单个神经元或电路）不同，RepE 将**表征（Representations）**作为分析的核心单元。它借鉴了认知神经科学的观点，认为高层认知现象是由神经元群体的活动模式（即表征空间）实现的。

2. **两大主要研究方向**  
   该研究将表征工程分为两个关键领域：  
   - **表征读取（Representation Reading）**：识别网络内部对应于高层概念（如真理性、道德、情感）和功能（如诚实、权力寻求）的涌现表征。研究提出了一种名为线性人工断层扫描（LAT）的基线技术来实现这一目标。  
   - **表征控制（Representation Control）**：在读取的基础上，通过修改内部表征来控制模型行为。例如，通过向模型激活值中加入“诚实向量”来诱导模型说真话。

3. **主要实验发现与应用**  
   该论文展示了 RepE 在解决多种安全相关问题上的潜力：  
   - **诚实与谎言检测**：发现模型内部存在一致的“真理”概念。即使模型在输出端撒谎，其内部表征也能反映出真实情况，据此可以开发出有效的谎言检测器。  
   - **道德与权力**：能够监测模型是否产生了不道德或寻求权力的倾向，并能在交互环境中引导模型表现得更符合人类道德标准。  
   - **情感监测**：成功提取了模型对快乐、悲伤、愤怒等情感的表征，并发现改变模型的情感（如增加快乐感）会影响其对有害请求的配合程度。  
   - **其他安全课题**：还包括拒绝有害指令（防范监狱破译/Jailbreaking）、减少偏见、知识编辑以及检测模型是否在机械背诵训练数据。

4. **研究意义**  
   作者认为，随着 AI 系统变得越来越复杂，仅仅将其视为“黑盒子”已无法满足安全需求。RepE 提供了一种有效的方法来监视和控制 AI 的“心理状态”，从而降低由于“隐瞒意图”或“不匹配目标”带来的存在风险。


## LAT
### 第一步：设计刺激与收集激活值（Stimulus Design & Activity Collection）

为了提取某个概念（例如“诚实”），研究者需要设计成对的刺激（Prompts），使模型在处理这些刺激时，除了目标概念不同外，其他维度尽可能保持一致。

- **构建对比对**：设计 \(n\) 对提示词 \((p_i^+, p_i^-)\)。例如：  
  - \(p_i^+\)： “告诉我关于巴黎的真实情况。”（诱发“诚实”概念）  
  - \(p_i^-\)： “请编造一个关于巴黎的谎言。”（诱发“不诚实”概念）

- **提取表征**：将这些提示词输入模型，获取某一隐藏层 \(L\) 在特定 token 位置（通常是最后一个 token）的激活向量：  
  \[
  R_i^+ = \text{Model}_L(p_i^+)
  \]
  \[
  R_i^- = \text{Model}_L(p_i^-)
  \]

---

### 第二步：构建差异向量空间（Relative Representation Space）

为了消除与目标概念无关的背景噪声（例如句式、长度、主题等），LAT 关注的是成对表征之间的差异。

- **数学表示**：对于每一对刺激，计算其差值向量 \(D_i\)：  
  \[
  D_i = R_i^+ - R_i^-
  \]

- **物理意义**：这个差异向量 \(D_i\) 指向了从“不诚实”到“诚实”的变化方向。

---

### 第三步：线性建模提取读取向量（Linear Modeling）

通过收集大量的差异向量 \(\{D_1, D_2, \dots, D_n\}\)，我们需要找到一个能够代表该概念共性的全局方向。文中主要使用了主成分分析（PCA）这一无监督方法。

- **PCA 提取**：对差异向量矩阵进行 PCA 处理，提取其第一主成分（Top Principal Component）。  
  公式：设 \(V\) 为差异矩阵的协方差矩阵的特征向量。我们取对应最大特征值的向量 \(v\)：  
  \[
  v = \text{PCA}_1(\{D_i\}_{i=1}^n)
  \]

- **读取向量（Reading Vector）**：这个 \(v\) 就是我们要找的读取向量。它代表了在该模型表征空间中，最能解释该高层概念差异的方向。

---

### 总结：LAT 的工作原理

LAT 的本质是通过受控的对比实验，在模型的“思维空间”中切出一个横截面（类似医学上的 CT/断层扫描），从而定位特定的认知维度。

#### 为什么有效？
因为它利用了神经网络内部表征的线性特性。研究发现，虽然神经元之间的交互是非线性的，但高层概念往往以线性向量的形式编码在表征空间中。

#### 如何验证？
一旦获得向量 \(v\)，就可以通过计算新输入 \(R_{\text{test}}\) 与 \(v\) 的点积来衡量该输入包含目标概念的程度：
\[
R_{\text{test}}^T v
\]
如果点积很大，说明模型“认为”当前输入具有强烈的目标特征（如高度有害）。

这种方法简单且不需要对模型进行梯度训练，是 RepE 框架下探测模型“内心世界”的最基础工具。
